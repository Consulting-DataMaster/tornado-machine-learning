{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/GAlogo.png\" style=\"float: left; margin: 15px; height: 100px\">\n",
    "\n",
    "# CAPSTONE PROJECT\n",
    "## US TORNADOES: PREDICTING THEIR MAGNITUDE WITH MACHINE LEARNING\n",
    "### Pre-Processing Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "Taking the pre-processing functions and work done in [part3](tornadoes_part3_eda_modelling_nlp_tsa.ipynb) and gathering them in a class to be used in production with pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import calendar\n",
    "from datetime import datetime, date, timedelta\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing class for data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When wanting to apply a process in production, it is important to make everyhting repeatable and with an easy implementation. We do not want to copy and past every single line of code and functions every single time new data needs to be predicted.\n",
    "- This is where a class is important. We can gather in it all the functions and pre-processing code we worked on in part 2 and 3 of the capstone. And then run all that in one go through fit and then transform. This is a more efficient way of working.\n",
    "- Moreover, it is then easily accessible in a pipeline in conjunction with standardization and modellong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# As we want to be able to integrate the class into an sklearn pipeline, we need to use \n",
    "# the modules BaseEstimator and TransformerMixin in the class construction:\n",
    "\n",
    "class TornadoPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.feature_names = []\n",
    "    \n",
    "    \n",
    "\n",
    "    def _compute_duration(self, df, beginDT='BEGIN_DATE_TIME', endDT='END_DATE_TIME'):\n",
    "        '''Takes a tornado dataframe in input, with dates and times of beginning and end of\n",
    "        a tornado, in text format.\n",
    "        Converts them into datatime format.\n",
    "        Computes the duration in minutes and returns it as new column\n",
    "        Computes the average date and average time, \n",
    "        Computes the day of the year, and time in floating format, and returns them as \n",
    "        new columns'''\n",
    "\n",
    "        # Changing to datetime format:\n",
    "        df[beginDT] = pd.to_datetime(df[beginDT])\n",
    "        df[endDT] = pd.to_datetime(df[endDT])\n",
    "\n",
    "        # Computes the duration:\n",
    "        df['Duration'] =  df[endDT] - df[beginDT]\n",
    "        # Converting to minutes from seconds:\n",
    "        df['Duration'] = df.Duration.map(lambda x: int(round(x.total_seconds()/60.)))\n",
    "\n",
    "        # Computing the average date and time of a tornado event:\n",
    "        df['AverageDate'] = pd.to_datetime(df[beginDT] + (df[endDT] - df[beginDT])/2)\n",
    "        df['AverageTime'] = df['AverageDate']\n",
    "\n",
    "        def _dayoftheyear(dateandtime):\n",
    "            '''converts a timestamp object into day of the year, taking leap years into account'''\n",
    "            dayYear = dateandtime.timetuple().tm_yday\n",
    "            # Feb 28 corresponds to year day 31+28=59\n",
    "            if calendar.isleap(dateandtime.year) and dayYear<=59:\n",
    "                return dayYear\n",
    "            # For dates superior or equal to Feb 29, for leap years, returns the value-1 \n",
    "            # for a number to always correspond\n",
    "            # to the same date for any year\n",
    "            elif calendar.isleap(dateandtime.year) and dayYear>59:\n",
    "                return dayYear - 1\n",
    "            # For non leap years:\n",
    "            else:\n",
    "                return dayYear\n",
    "        # Converting date to day of the year:\n",
    "        df['AverageDate'] = df['AverageDate'].map(_dayoftheyear)\n",
    "\n",
    "        # Converting time to float from Timestamp object:\n",
    "        df['AverageTime'] = df['AverageTime'].map(lambda x: x.time())\n",
    "        df['AverageTime'] = df['AverageTime'].map(lambda x: x.hour) \\\n",
    "        + df['AverageTime'].map(lambda x: round((x.minute*100/60.)/100., 2)) \\\n",
    "        + df['AverageTime'].map(lambda x: round((x.second*100/60.)/10000., 4))\n",
    "    \n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def _death_and_injuries(self, df):\n",
    "        '''Gathers indirect and direct injuries and deaths into one column for each'''\n",
    "        df['Deaths'] = df.DEATHS_DIRECT + df.DEATHS_INDIRECT\n",
    "        df['Injuries'] = df.INJURIES_DIRECT + df.INJURIES_INDIRECT\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def _compute_Az_AvLat_AvLon_fromLatLong(self, df, xA='BEGIN_LON', yA='BEGIN_LAT', \n",
    "                                            xB='END_LON', yB='END_LAT',\n",
    "                                            outMeanLat='Mean_Lat', outMeanLon='Mean_Lon',\n",
    "                                            outAz='Azimuth'):\n",
    "        '''Takes a tornado dataframe in input, with geographical coordinates of beginning and \n",
    "        end points.\n",
    "        Returns the dataframe with 3 new features: \n",
    "        direction the tornado headed from North (azimuth of its rectiligne path)\n",
    "        average latitude\n",
    "        average longitude'''\n",
    "\n",
    "        # New features with average latitude and longitude of the tornado path:\n",
    "        LAT = (df[yA]+df[yB])/2\n",
    "        LON = (df[xA]+df[xB])/2\n",
    "        df[outMeanLat] = np.round(LAT,4)\n",
    "        df[outMeanLon] = np.round(LON,4)\n",
    "\n",
    "        # Coordinates differences converted to radians:\n",
    "        diffLON = np.radians(df[xB] - df[xA])\n",
    "        diffLAT = np.radians(df[yB] - df[yA])\n",
    "\n",
    "        # Azimuth computed from trigonometry (arctan2 allows getting the angle in range (-pi,pi) \n",
    "        # instead of (-pi/2,pi/2) like with conventional arctan):\n",
    "        AZ = pd.Series(index=diffLON.index)\n",
    "        for i in range(len(diffLON)):\n",
    "            if diffLAT[i]==0 and diffLON[i]==0:\n",
    "                AZ[i] = np.nan\n",
    "            else:\n",
    "                AZ[i] = np.degrees(np.arctan2(diffLON[i],diffLAT[i]))\n",
    "\n",
    "        # Saving azimuth into new column:\n",
    "        df[outAz] = np.round(AZ,2)\n",
    "\n",
    "        # Let's make the North as the middle of the range => angles from ]-pi;pi] instead \n",
    "        # of [0;2pi[\n",
    "        df[outAz] = df[outAz].map(lambda x: x-360 if x>180 else x)\n",
    "        \n",
    "        # Filling the azimuth NaN values with median:\n",
    "        df[outAz].fillna(df['Azimuth'].median(), inplace=True)\n",
    "\n",
    "        return df\n",
    "    \n",
    "\n",
    "    def _fips_to_state_abbreviation(self, df):\n",
    "        '''Transforming the state FIPS numbers into shorter official abbreviations'''\n",
    "        fips_to_state = {1: 'AL', 2: 'AK', 4: 'AZ', 5: 'AR', 6: 'CA', 8: 'CO', 9: 'CT', 10: 'DE',\n",
    "                         11: 'DC', 12: 'FL', 13: 'GA', 15: 'HI', 16: 'ID', 17: 'IL', 18: 'IN', \n",
    "                         19: 'IA', 20: 'KS',\n",
    "                         21: 'KY', 22: 'LA', 23: 'ME', 24: 'MD', 25: 'MA', 26: 'MI', 27: 'MN', \n",
    "                         28: 'MS', 29: 'MO', 30: 'MT',\n",
    "                         31: 'NE', 32: 'NV', 33: 'NH', 34: 'NJ', 35: 'NM', 36: 'NY', 37: 'NC',\n",
    "                         38: 'ND', 39: 'OH', 40: 'OK',\n",
    "                         41: 'OR', 42: 'PA', 44: 'RI', 45: 'SC', 46: 'SD', 47: 'TN', 48: 'TX',\n",
    "                         49: 'UT', 50: 'VT',\n",
    "                         51: 'VA', 53: 'WA', 54: 'WV', 55: 'WI', 56: 'WY', 60: 'AS',\n",
    "                         64: 'FM', 66: 'GU', 68: 'MH', 69: 'MP', 70: 'PW',\n",
    "                         72: 'PR', 74: 'UM', 78: 'VI',\n",
    "                         99: 'PR'}\n",
    "        df['State'] = df['STATE_FIPS'].map(lambda x: fips_to_state[x])\n",
    "        return df\n",
    "\n",
    "    \n",
    "    def _compute_total_cost(self, df):\n",
    "        '''Converting the cost columns into integer numbers'''\n",
    "        \n",
    "        def _convertcost_tointeger(cost):\n",
    "            '''From a cost in float or text format in format 'nb'letter' where letter = K or M or B\n",
    "            Returns a cost as integer'''\n",
    "            try:\n",
    "                cost=int(cost)\n",
    "                return cost\n",
    "            except:\n",
    "                if pd.isnull(cost): return 0\n",
    "                elif 'K' in cost: return int(round(float(cost[:-1]) * 10**3))\n",
    "                elif 'M' in cost: return int(round(float(cost[:-1]) * 10**6))\n",
    "                elif 'B' in cost: return int(round(float(cost[:-1]) * 10**9))\n",
    "                else: return np.nan\n",
    "                \n",
    "#        def _convertcost_tointeger(cost):\n",
    "#            '''From a cost in text format in format 'nb'.00'letter' where letter = K or M or B\n",
    "#            Returns a cost as integer'''\n",
    "#            if pd.isnull(cost): return 0\n",
    "#            elif 'K' in cost: return int(round(float(cost[:-2]) * 10**3))\n",
    "#            elif 'M' in cost: return int(round(float(cost[:-2]) * 10**6))\n",
    "#            elif 'B' in cost: return int(round(float(cost[:-2]) * 10**9))\n",
    "#            else: return np.nan\n",
    "            \n",
    "        # Converting the cost columns into integer numbers and summing them\n",
    "        df['TotalCost'] = df.DAMAGE_PROPERTY.map(_convertcost_tointeger) + \\\n",
    "                          df.DAMAGE_CROPS.map(_convertcost_tointeger)\n",
    "        return df\n",
    "\n",
    "\n",
    "    def _replace_spaces_in_source(self, df):\n",
    "        # Replacing spaces by underscores in the SOURCE feature:\n",
    "        df['Source'] = df.SOURCE.map(lambda x: x.replace(' ', '_'))\n",
    "        return df\n",
    "\n",
    "\n",
    "    def _drop_unused_cols(self, df):\n",
    "        for col in ['EVENT_ID', 'EPISODE_ID', 'EVENT_TYPE', 'MAGNITUDE', 'MAGNITUDE_TYPE',\n",
    "                    'FLOOD_CAUSE', \n",
    "                    'EPISODE_NARRATIVE', 'EVENT_NARRATIVE', 'DATA_SOURCE', 'CATEGORY',\n",
    "                    'BEGIN_YEARMONTH', 'BEGIN_DAY', 'BEGIN_TIME', \n",
    "                    'END_YEARMONTH', 'END_DAY', 'END_TIME',\n",
    "                    'BEGIN_DATE_TIME', 'CZ_TIMEZONE', 'END_DATE_TIME', 'YEAR', 'MONTH_NAME',\n",
    "                    'DEATHS_DIRECT','DEATHS_INDIRECT','INJURIES_DIRECT','INJURIES_INDIRECT',\n",
    "                    'BEGIN_RANGE', 'BEGIN_AZIMUTH', 'END_RANGE', 'END_AZIMUTH', \n",
    "                    'BEGIN_LAT', 'BEGIN_LON', 'END_LAT', 'END_LON', \n",
    "                    'CZ_NAME', 'CZ_TYPE', 'CZ_FIPS', 'WFO', 'STATE_FIPS', 'STATE', \n",
    "                    'BEGIN_LOCATION', 'END_LOCATION', \n",
    "                    'TOR_OTHER_CZ_STATE', 'TOR_OTHER_CZ_FIPS', 'TOR_OTHER_CZ_NAME', \n",
    "                    'TOR_OTHER_WFO', 'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'SOURCE']:\n",
    "            try:\n",
    "                df = df.drop(col, axis=1)\n",
    "            except:\n",
    "                pass\n",
    "        return df\n",
    "\n",
    "    \n",
    "    def transform(self, X, *args):\n",
    "        X = self._compute_duration(X)\n",
    "        X = self._death_and_injuries(X)\n",
    "        X = self._compute_Az_AvLat_AvLon_fromLatLong(X)\n",
    "        X = self._fips_to_state_abbreviation(X)\n",
    "        X = self._compute_total_cost(X)\n",
    "        X = self._replace_spaces_in_source(X)\n",
    "        X = self._drop_unused_cols(X)\n",
    "        self.feature_names = X.columns\n",
    "        return X\n",
    "\n",
    "    \n",
    "    def fit(self, X, *args):\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the class with our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EF0    7661\n",
       "EF1    4822\n",
       "EF2    1441\n",
       "EF3     435\n",
       "EF4     103\n",
       "EFU      62\n",
       "EF5      14\n",
       "Name: TOR_F_SCALE, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating engine connection to my local \"storms\" database, using sqlalchemy:\n",
    "engine_local = create_engine('postgresql://localhost:5432/storms')\n",
    "\n",
    "# Saving the data from Feb 2007 until now (since the EF scale has been in place):\n",
    "sql_query = \"\"\"\n",
    "SELECT * \n",
    "FROM tornadoes_1950_mid2017 \n",
    "WHERE \"BEGIN_YEARMONTH\" >= 200702;\n",
    "\"\"\"\n",
    "\n",
    "raw_2007_2017 = pd.read_sql(sql_query, engine_local)\n",
    "\n",
    "# Counting the number of tornadoes in each magnitude category:\n",
    "raw_2007_2017.TOR_F_SCALE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TornadoPreprocessor()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc = TornadoPreprocessor()\n",
    "preproc.fit(raw_2007_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = preproc.transform(raw_2007_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14538, 62) (14538, 14)\n"
     ]
    }
   ],
   "source": [
    "print raw_2007_2017.shape, df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOR_F_SCALE</th>\n",
       "      <th>TOR_LENGTH</th>\n",
       "      <th>TOR_WIDTH</th>\n",
       "      <th>Duration</th>\n",
       "      <th>AverageDate</th>\n",
       "      <th>AverageTime</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Injuries</th>\n",
       "      <th>Mean_Lat</th>\n",
       "      <th>Mean_Lon</th>\n",
       "      <th>Azimuth</th>\n",
       "      <th>State</th>\n",
       "      <th>TotalCost</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EF0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>208</td>\n",
       "      <td>15.855</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.7345</td>\n",
       "      <td>-93.3220</td>\n",
       "      <td>120.34</td>\n",
       "      <td>IA</td>\n",
       "      <td>0</td>\n",
       "      <td>Public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EF0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>208</td>\n",
       "      <td>16.255</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.6694</td>\n",
       "      <td>-93.0534</td>\n",
       "      <td>117.98</td>\n",
       "      <td>IA</td>\n",
       "      <td>0</td>\n",
       "      <td>Law_Enforcement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EF1</td>\n",
       "      <td>0.29</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>208</td>\n",
       "      <td>15.575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.7892</td>\n",
       "      <td>-93.5405</td>\n",
       "      <td>144.90</td>\n",
       "      <td>IA</td>\n",
       "      <td>60000</td>\n",
       "      <td>Trained_Spotter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EF0</td>\n",
       "      <td>1.43</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>15.685</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.2945</td>\n",
       "      <td>-98.6804</td>\n",
       "      <td>1.11</td>\n",
       "      <td>KS</td>\n",
       "      <td>0</td>\n",
       "      <td>Law_Enforcement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EF0</td>\n",
       "      <td>1.38</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5</td>\n",
       "      <td>183</td>\n",
       "      <td>17.535</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.7200</td>\n",
       "      <td>-80.2500</td>\n",
       "      <td>0.00</td>\n",
       "      <td>FL</td>\n",
       "      <td>0</td>\n",
       "      <td>Broadcast_Media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EF0</td>\n",
       "      <td>2.77</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9</td>\n",
       "      <td>111</td>\n",
       "      <td>18.875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.6830</td>\n",
       "      <td>-98.3963</td>\n",
       "      <td>81.93</td>\n",
       "      <td>SD</td>\n",
       "      <td>0</td>\n",
       "      <td>Storm_Chaser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EF0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>11.925</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.6658</td>\n",
       "      <td>-81.5240</td>\n",
       "      <td>-36.57</td>\n",
       "      <td>FL</td>\n",
       "      <td>20000</td>\n",
       "      <td>NWS_Storm_Survey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EF2</td>\n",
       "      <td>1.50</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>6.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.5300</td>\n",
       "      <td>-82.2500</td>\n",
       "      <td>64.12</td>\n",
       "      <td>FL</td>\n",
       "      <td>0</td>\n",
       "      <td>NWS_Storm_Survey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EF1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>9.170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.7200</td>\n",
       "      <td>-81.2400</td>\n",
       "      <td>64.12</td>\n",
       "      <td>FL</td>\n",
       "      <td>0</td>\n",
       "      <td>Public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EF1</td>\n",
       "      <td>3.47</td>\n",
       "      <td>150.0</td>\n",
       "      <td>5</td>\n",
       "      <td>295</td>\n",
       "      <td>16.935</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.4369</td>\n",
       "      <td>-90.5177</td>\n",
       "      <td>52.84</td>\n",
       "      <td>MS</td>\n",
       "      <td>180000</td>\n",
       "      <td>NWS_Storm_Survey</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TOR_F_SCALE  TOR_LENGTH  TOR_WIDTH  Duration  AverageDate  AverageTime  \\\n",
       "0         EF0        0.27       20.0         1          208       15.855   \n",
       "1         EF0        0.20       20.0         1          208       16.255   \n",
       "2         EF1        0.29      100.0         1          208       15.575   \n",
       "3         EF0        1.43       50.0         3          126       15.685   \n",
       "4         EF0        1.38       20.0         5          183       17.535   \n",
       "5         EF0        2.77      100.0         9          111       18.875   \n",
       "6         EF0        0.55       30.0         1          152       11.925   \n",
       "7         EF2        1.50      300.0         0          105        6.250   \n",
       "8         EF1        0.20       50.0         0          105        9.170   \n",
       "9         EF1        3.47      150.0         5          295       16.935   \n",
       "\n",
       "   Deaths  Injuries  Mean_Lat  Mean_Lon  Azimuth State  TotalCost  \\\n",
       "0       0         0   41.7345  -93.3220   120.34    IA          0   \n",
       "1       0         0   41.6694  -93.0534   117.98    IA          0   \n",
       "2       0         0   41.7892  -93.5405   144.90    IA      60000   \n",
       "3       0         0   37.2945  -98.6804     1.11    KS          0   \n",
       "4       0         0   26.7200  -80.2500     0.00    FL          0   \n",
       "5       0         0   43.6830  -98.3963    81.93    SD          0   \n",
       "6       0         0   24.6658  -81.5240   -36.57    FL      20000   \n",
       "7       0         0   30.5300  -82.2500    64.12    FL          0   \n",
       "8       0         0   29.7200  -81.2400    64.12    FL          0   \n",
       "9       0         0   33.4369  -90.5177    52.84    MS     180000   \n",
       "\n",
       "             Source  \n",
       "0            Public  \n",
       "1   Law_Enforcement  \n",
       "2   Trained_Spotter  \n",
       "3   Law_Enforcement  \n",
       "4   Broadcast_Media  \n",
       "5      Storm_Chaser  \n",
       "6  NWS_Storm_Survey  \n",
       "7  NWS_Storm_Survey  \n",
       "8            Public  \n",
       "9  NWS_Storm_Survey  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class works as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class and all the packages import are also copied into a .py file inside the current folder so that it is easily accessible in other notebooks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
